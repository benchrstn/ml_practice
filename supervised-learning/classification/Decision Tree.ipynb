{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ada2955-1c6c-43f8-93e4-dc2d38a6df87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f67ddcb-e774-45ef-b6cd-05e5fd2bc981",
   "metadata": {},
   "source": [
    "# Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f5411e9-8ca8-49f5-8bd5-17d63824ec67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "data = datasets.load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c7f081-3138-4c7e-b702-4deeccfdfdaa",
   "metadata": {},
   "source": [
    "# Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c09d1ef-d659-4939-9d3a-6971e07f03ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "data = datasets.load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "model = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=2)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e7453d-e9c8-42ea-83bf-d2de4a4ff8e8",
   "metadata": {},
   "source": [
    "Tree models like decision tree don't need feature scaling to operate effectively. It used threshold for the split decision, unlike KNN and SVM that used distance metric. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fdbd62-c185-439c-a5fd-577766576665",
   "metadata": {},
   "source": [
    "# Wine Quality Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12b850ec-c5bc-412c-a2c2-34b813150270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red = pd.read_csv('datasets/winequality-red.csv', sep=';')\n",
    "white = pd.read_csv('datasets/winequality-white.csv', sep=';')\n",
    "\n",
    "combined = pd.concat([red, white])\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f53d31-7957-4c7a-b18e-42271b5558fd",
   "metadata": {},
   "source": [
    "## Classification Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af6ea04-fb63-4b77-a92e-a68e51b5dac6",
   "metadata": {},
   "source": [
    "just like other algorithms, wine quality can be approached from both classification and regression problem. For the classification approach, we are going to make it into binary classification problem by changing quality > 6 as 1 and quality < 7 as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f06eaa7-4467-4cf5-a267-447181ab24ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8161538461538461\n"
     ]
    }
   ],
   "source": [
    "X = combined.drop('quality', axis=1)\n",
    "y = (combined['quality']>6).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1)\n",
    "\n",
    "model = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=2)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a0c665-6c29-411a-8a61-df9b628bf7e6",
   "metadata": {},
   "source": [
    "## Regression Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6d4fde-94e8-40c1-900d-2f188d66a082",
   "metadata": {},
   "source": [
    "for the regression, the quality will also be the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52318d72-9578-40de-adcf-2fdf95bbd4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2, 0.230809\n",
      "MSE 0.5595392585130958\n"
     ]
    }
   ],
   "source": [
    "X = combined.drop('quality', axis=1)\n",
    "y = combined['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1)\n",
    "\n",
    "model = DecisionTreeRegressor(criterion='squared_error', max_depth=3, random_state=2)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"R2, {r2_score(y_test, y_pred):2f}\")\n",
    "print('MSE', mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d50544-9ed5-4757-897f-2ec83e668cdc",
   "metadata": {},
   "source": [
    "just like the results on the other notebooks, the performance are better for the classification approach than the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe410a6-108e-41e1-8de8-ae3de04632c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
