{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b64885e-3e45-4211-9f16-020f0da25d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss, TomekLinks\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bdc67e-531d-42ab-996d-63aab33243dd",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "845cd82e-962a-46f1-a355-ca311772974a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('diabetes.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18a2ac14-d15c-451c-9810-196d5d2f196c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "0    500\n",
       "1    268\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Outcome.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c62949-1ba3-4f8f-87e6-a5b06d20ca0a",
   "metadata": {},
   "source": [
    "We use diabetes dataset that is imbalanced, with class 0 568 and class 1 268"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66a6f16-daa3-40cb-8188-8e9e6f499f98",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3345bfd-8bce-4220-b4cb-823dd94eba06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: Counter({0: 350, 1: 187})\n"
     ]
    }
   ],
   "source": [
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=1)\n",
    "\n",
    "print('Original class distribution:', Counter(y_train))\n",
    "\n",
    "#dictionary to store results\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f076efb8-dcbf-4e7a-a936-5fb60b8c7564",
   "metadata": {},
   "source": [
    "When performing any feature engineering, including resampling, we always split the train test data first. We can only do feature engineering on training data, the test data needs to be untouched because it acts as an unseen / new data.\n",
    "\n",
    "For this practice, we use the parameter \"stratify = y\" for the train test split so that the split will follow the distribution of y from the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44e2cd0-2078-4173-93ae-926927625965",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "### Baseline (no sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a9819c9-7363-4478-99a9-4723e7de982a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== No Sampling ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.80       150\n",
      "           1       0.65      0.52      0.58        81\n",
      "\n",
      "    accuracy                           0.73       231\n",
      "   macro avg       0.71      0.68      0.69       231\n",
      "weighted avg       0.72      0.73      0.72       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#save the result\n",
    "results['No Sampling'] = f1_score(y_test, y_pred, average='macro')\n",
    "print('\\n=== No Sampling ===')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ae1ce5-11e1-47a7-a2aa-27e431d73f35",
   "metadata": {},
   "source": [
    "### SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc08f295-ca07-47ab-aee8-5ad97407c2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After SMOTE: Counter({1: 350, 0: 350})\n",
      "\n",
      "=== SMOTE Sampling ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79       150\n",
      "           1       0.61      0.63      0.62        81\n",
      "\n",
      "    accuracy                           0.73       231\n",
      "   macro avg       0.71      0.71      0.71       231\n",
      "weighted avg       0.73      0.73      0.73       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=1)\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After SMOTE:\", Counter(y_smote))\n",
    "\n",
    "clf.fit(X_smote, y_smote)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#save the result\n",
    "results['SMOTE Sampling'] = f1_score(y_test, y_pred, average='macro')\n",
    "print('\\n=== SMOTE Sampling ===')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3884c37c-c711-43db-bbcc-84998acfd433",
   "metadata": {},
   "source": [
    "### Borderline SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "057be19d-5fab-4712-8cf9-3a271320c08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After BSMOTE: Counter({1: 350, 0: 350})\n",
      "\n",
      "=== BSMOTE Sampling ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.78       150\n",
      "           1       0.60      0.64      0.62        81\n",
      "\n",
      "    accuracy                           0.72       231\n",
      "   macro avg       0.70      0.70      0.70       231\n",
      "weighted avg       0.73      0.72      0.73       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bsmote = BorderlineSMOTE(random_state=1)\n",
    "X_bsmote, y_bsmote = bsmote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After BSMOTE:\", Counter(y_bsmote))\n",
    "\n",
    "clf.fit(X_bsmote, y_bsmote)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#save the result\n",
    "results['BSMOTE Sampling'] = f1_score(y_test, y_pred, average='macro')\n",
    "print('\\n=== BSMOTE Sampling ===')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a9f63a-605a-41b6-99b2-7fe27db7a6ea",
   "metadata": {},
   "source": [
    "### Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b017c85-c498-4767-99ff-d0f1ad63b46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After RUS: Counter({0: 187, 1: 187})\n",
      "\n",
      "=== Random Under Sampling ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.72      0.77       150\n",
      "           1       0.58      0.72      0.64        81\n",
      "\n",
      "    accuracy                           0.72       231\n",
      "   macro avg       0.70      0.72      0.70       231\n",
      "weighted avg       0.74      0.72      0.72       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rus = RandomUnderSampler(random_state=1)\n",
    "X_rus, y_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After RUS:\", Counter(y_rus))\n",
    "\n",
    "clf.fit(X_rus, y_rus)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#save the result\n",
    "results['Random Under Sampling'] = f1_score(y_test, y_pred, average='macro')\n",
    "print('\\n=== Random Under Sampling ===')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d245cc48-66c8-4c31-99a2-e0575c99ee9b",
   "metadata": {},
   "source": [
    "### Near Miss Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad0b07c4-7dad-44a3-a37a-4b1bf71e74cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After NearMiss: Counter({0: 187, 1: 187})\n",
      "\n",
      "=== NearMiss Sampling ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79       150\n",
      "           1       0.61      0.69      0.65        81\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.71      0.73      0.72       231\n",
      "weighted avg       0.75      0.74      0.74       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nm = NearMiss(version=1)\n",
    "X_nm, y_nm = nm.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After NearMiss:\", Counter(y_nm))\n",
    "\n",
    "clf.fit(X_nm, y_nm)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#save the result\n",
    "results['NearMiss Sampling'] = f1_score(y_test, y_pred, average='macro')\n",
    "print('\\n=== NearMiss Sampling ===')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70cdea6-8365-48e5-916f-4fcffc2b2ba1",
   "metadata": {},
   "source": [
    "### SMOTE + Tomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f43e6fc-a41c-4949-8ddc-f9299aa504cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After SMOTETomek: Counter({1: 326, 0: 326})\n",
      "\n",
      "=== SMOTETomek Sampling ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79       150\n",
      "           1       0.61      0.63      0.62        81\n",
      "\n",
      "    accuracy                           0.73       231\n",
      "   macro avg       0.71      0.71      0.71       231\n",
      "weighted avg       0.73      0.73      0.73       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smote_tomek = SMOTETomek(random_state=1)\n",
    "X_st, y_st = smote_tomek.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After SMOTETomek:\", Counter(y_st))\n",
    "\n",
    "clf.fit(X_st, y_st)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#save the result\n",
    "results['SMOTETomek Sampling'] = f1_score(y_test, y_pred, average='macro')\n",
    "print('\\n=== SMOTETomek Sampling ===')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170e7cd5-45d2-4d05-a5d6-11a6263f9bb7",
   "metadata": {},
   "source": [
    "### SMOTE + ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0bb6cb8-e166-47a3-9037-557efd4672cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After SMOTEENN: Counter({1: 217, 0: 178})\n",
      "\n",
      "=== SMOTEENN Sampling ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.74      0.78       150\n",
      "           1       0.60      0.73      0.66        81\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.72      0.73      0.72       231\n",
      "weighted avg       0.75      0.74      0.74       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smote_enn = SMOTEENN(random_state=1)\n",
    "X_se, y_se = smote_enn.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After SMOTEENN:\", Counter(y_se))\n",
    "\n",
    "clf.fit(X_se, y_se)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#save the result\n",
    "results['SMOTEENN Sampling'] = f1_score(y_test, y_pred, average='macro')\n",
    "print('\\n=== SMOTEENN Sampling ===')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f207a96-54f2-4284-84aa-ba04b4d4e136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COMPARISON ===\n",
      "SMOTEENN Sampling: 0.7218\n",
      "NearMiss Sampling: 0.7182\n",
      "SMOTE Sampling: 0.7069\n",
      "SMOTETomek Sampling: 0.7069\n",
      "Random Under Sampling: 0.7048\n",
      "BSMOTE Sampling: 0.7007\n"
     ]
    }
   ],
   "source": [
    "# Compare all results\n",
    "print(\"\\n=== COMPARISON ===\")\n",
    "for method, score in sorted(results.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{method}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3a5fac-fd51-4998-8873-962b701ce47f",
   "metadata": {},
   "source": [
    "Common misconception, when doing combinations of SMOTE + Tomek or ENN, the result is not just an oversampling but there is also reduction, so the number is less than SMOTE alone\n",
    "1. SMOTE generates synthetic samples along lines between minority samples, some of them are very close to majority sample and it create overlap at boundary\n",
    "2. These synthetic samples form Tomek Links with majority samples\n",
    "3. Tomek / ENN sampling removes majority samples in Tomek links and it also remove samples that are in the wrong neighbourhood (ENN)\n",
    "\n",
    "One thing to know, Tomek & ENN can also remove minority sampling for this case specificly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eecbea7-1d97-4d58-9ee7-b3ded5f7ff75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
